{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ðŸŽ¬ Task 2: IMDB Sentiment Analysis using Logistic Regression\n",
        "In this task, we classify IMDB movie reviews as positive or negative using Logistic Regression after text cleaning and TF-IDF vectorization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import TreebankWordTokenizer\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\Taha\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\Taha\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     C:\\Users\\Taha\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Download necessary NLTK resources\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸ“¥ Load the Dataset\n",
        "Ensure 'IMDB.csv' is in the working directory with columns: `review`, `sentiment`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                              review sentiment\n",
            "0  One of the other reviewers has mentioned that ...  positive\n",
            "1  A wonderful little production. <br /><br />The...  positive\n",
            "2  I thought this was a wonderful way to spend ti...  positive\n",
            "3  Basically there's a family where a little boy ...  negative\n",
            "4  Petter Mattei's \"Love in the Time of Money\" is...  positive\n"
          ]
        }
      ],
      "source": [
        "# Load and check data\n",
        "df = pd.read_csv(\"IMDB.csv\")\n",
        "df = df[['review', 'sentiment']]\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸ§¼ Label Encoding & Cleaning\n",
        "- Map sentiment to binary (positive: 1, negative: 0)\n",
        "- Clean text using regex, remove HTML, tokenize, and lemmatize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "label\n",
            "1    25000\n",
            "0    25000\n",
            "Name: count, dtype: int64\n",
            "                                          clean_text  label\n",
            "0  one reviewer mentioned watching oz episode you...      1\n",
            "1  wonderful little production br br filming tech...      1\n",
            "2  thought wonderful way spend time hot summer we...      1\n",
            "3  basically there family little boy jake think t...      0\n",
            "4  petter matteis love time money visually stunni...      1\n"
          ]
        }
      ],
      "source": [
        "df['label'] = df['sentiment'].map({'positive': 1, 'negative': 0})\n",
        "df.dropna(subset=['label'], inplace=True)\n",
        "print(df['label'].value_counts())\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "tokenizer = TreebankWordTokenizer()\n",
        "\n",
        "def clean_text(text):\n",
        "    text = str(text).lower()\n",
        "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", '', text)\n",
        "    text = re.sub(r'[^a-z\\s]', '', text)\n",
        "    text = re.sub(r'<.*?>', '', text)\n",
        "    tokens = tokenizer.tokenize(text)\n",
        "    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]\n",
        "    return \" \".join(tokens)\n",
        "\n",
        "# Apply cleaning\n",
        "df['clean_text'] = df['review'].apply(clean_text)\n",
        "print(df[['clean_text', 'label']].head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸ”  TF-IDF Vectorization and Splitting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification Report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.87      0.88      4961\n",
            "           1       0.88      0.90      0.89      5039\n",
            "\n",
            "    accuracy                           0.88     10000\n",
            "   macro avg       0.88      0.88      0.88     10000\n",
            "weighted avg       0.88      0.88      0.88     10000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "vectorizer = TfidfVectorizer(max_features=5000)\n",
        "X = vectorizer.fit_transform(df['clean_text'])\n",
        "y = df['label'].values\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "print(\"Classification Report:\\n\")\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸ§ª Predict Sentiment on Custom Text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Negative\n",
            "Positive\n"
          ]
        }
      ],
      "source": [
        "def predict_sentiment(text):\n",
        "    cleaned = clean_text(text)\n",
        "    vectorized = vectorizer.transform([cleaned])\n",
        "    prediction = model.predict(vectorized)[0]\n",
        "    return \"Positive\" if prediction == 1 else \"Negative\"\n",
        "\n",
        "# Example Predictions\n",
        "print(predict_sentiment(\"I hated this movie. It was boring and slow.\"))\n",
        "print(predict_sentiment(\"This movie was amazing, the acting was top-notch!\"))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
